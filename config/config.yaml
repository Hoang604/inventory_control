env:
  state_dim: 33
  action_dim: 3
intermediate_dim: 1024
actor:
  log_std_max: 2
  log_std_min: -20
  output_dim: 6
iql:
  learning_rate: 1e-4
  actor_learning_rate: 3e-6
  eta_min: 1e-7
  tau: 0.8
  gamma: 0.99
  alpha: 0.005
  beta: 1.0
training:
  batch_size: 512
  epochs: 100
  reward_scale: 0.1
  validation_split: 0.8
  seed: 42
  grad_norm_clip: 1.0
  adv_weight_clip: 100.0
  log_interval: 1
  checkpoint_interval: 5
