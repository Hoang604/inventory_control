actor:
  log_std_max: 2
  log_std_min: -20
  output_dim: 6
env:
  action_dim: 3
  state_dim: 33
intermediate_dim: 1024
iql:
  alpha: 0.005
  beta: 1.0
  eta_min: 1e-7
  gamma: 0.99
  learning_rate: 3e-6
  tau: 0.8
training:
  adv_weight_clip: 100.0
  batch_size: 512
  checkpoint_interval: 5
  epochs: 100
  grad_norm_clip: 1.0
  log_interval: 100
  reward_scale: 0.1
  seed: 42
  validation_split: 0.8
